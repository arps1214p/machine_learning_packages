{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 27569,
          "sourceType": "datasetVersion",
          "datasetId": 1408
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arps1214p/machine_learning_packages/blob/main/default_resnet_early_stopping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 라이브러리 Import 및 환경 설정"
      ],
      "metadata": {
        "id": "ePPCrszdeT3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "\n",
        "import math\n",
        "import random\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from skimage import io\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"PyTorch Version: \", torch.__version__)\n",
        "print(\"Torchvision Version: \", torchvision.__version__)\n",
        "print(\"Pillow Version: \", PIL.__version__)\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')\n",
        "\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:02:11.832685Z",
          "iopub.execute_input": "2025-05-17T13:02:11.833379Z",
          "iopub.status.idle": "2025-05-17T13:02:20.617602Z",
          "shell.execute_reply.started": "2025-05-17T13:02:11.833353Z",
          "shell.execute_reply": "2025-05-17T13:02:20.616951Z"
        },
        "id": "v-6BiFxbeT3v"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 가져오기"
      ],
      "metadata": {
        "id": "iBu_aowQeT3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"alexattia/the-simpsons-characters-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "train_dir = Path('/kaggle/input/the-simpsons-characters-dataset/simpsons_dataset/simpsons_dataset/')\n",
        "test_dir = Path('/kaggle/input/the-simpsons-characters-dataset/kaggle_simpson_testset/kaggle_simpson_testset/')"
      ],
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:02:58.407938Z",
          "iopub.execute_input": "2025-05-17T13:02:58.408485Z",
          "iopub.status.idle": "2025-05-17T13:02:58.412013Z",
          "shell.execute_reply.started": "2025-05-17T13:02:58.408464Z",
          "shell.execute_reply": "2025-05-17T13:02:58.411235Z"
        },
        "id": "AvGiey3zeT3z"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 함수 및 클래스 정의"
      ],
      "metadata": {
        "id": "fY8P2I5leT31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train-val split 및 testset 가져오기"
      ],
      "metadata": {
        "id": "zTdoOnPReT32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainValTestSplit():\n",
        "\n",
        "  def __init__(self, train_dir, test_dir):\n",
        "\n",
        "    self.train_dir = train_dir\n",
        "    self.test_dir = test_dir\n",
        "    # 하위 디렉토리를 순회하며 이미지의 경로를 리스트로 저장\n",
        "    self.train_val_files_path = sorted(list(self.train_dir.rglob('*.jpg')))\n",
        "    self.test_path = sorted(list(self.test_dir.rglob('*.jpg')))\n",
        "    self.train_val_labels = [path.parent.name for path in self.train_val_files_path]\n",
        "\n",
        "  def get_path(self):\n",
        "\n",
        "    train_files_path, val_files_path = train_test_split(self.train_val_files_path, test_size = 0.3, \\\n",
        "                                          stratify=self.train_val_labels, random_state = 42)\n",
        "\n",
        "    train_val_files_path = {'train': train_files_path, 'val': val_files_path}\n",
        "\n",
        "    return train_val_files_path, self.test_path\n",
        "\n",
        "  def get_n_classes(self):\n",
        "    return len(np.unique(self.train_val_labels))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:03:01.242076Z",
          "iopub.execute_input": "2025-05-17T13:03:01.242349Z",
          "iopub.status.idle": "2025-05-17T13:03:01.24793Z",
          "shell.execute_reply.started": "2025-05-17T13:03:01.242332Z",
          "shell.execute_reply": "2025-05-17T13:03:01.247056Z"
        },
        "id": "JubpBaA6eT32"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "TrainValTestPath = TrainValTestSplit(train_dir, test_dir)\n",
        "train_path, test_path = TrainValTestPath.get_path()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:03:05.819586Z",
          "iopub.execute_input": "2025-05-17T13:03:05.81988Z",
          "iopub.status.idle": "2025-05-17T13:04:04.268554Z",
          "shell.execute_reply.started": "2025-05-17T13:03:05.81986Z",
          "shell.execute_reply": "2025-05-17T13:04:04.267975Z"
        },
        "id": "yS27O_mbeT33"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습 함수"
      ],
      "metadata": {
        "id": "MBpUDxkQeT33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 조기종료 함수\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_val_loss = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        # Check if validation loss is nan\n",
        "        if np.isnan(val_loss):\n",
        "            self.trace_func(\"Validation loss is NaN. Ignoring this epoch.\")\n",
        "            return\n",
        "\n",
        "        if self.best_val_loss is None:\n",
        "            self.best_val_loss = val_loss\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif val_loss < self.best_val_loss - self.delta:\n",
        "            # Significant improvement detected\n",
        "            self.best_val_loss = val_loss\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0  # Reset counter since improvement occurred\n",
        "        else:\n",
        "            # No significant improvement\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decreases.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:04:04.269651Z",
          "iopub.execute_input": "2025-05-17T13:04:04.26992Z",
          "iopub.status.idle": "2025-05-17T13:04:04.278073Z",
          "shell.execute_reply.started": "2025-05-17T13:04:04.269903Z",
          "shell.execute_reply": "2025-05-17T13:04:04.277292Z"
        },
        "id": "uaOd4w1reT34"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, dataloaders, cost, optimizer, save_best_weights_path, save_last_weights_path, best_acc, num_epochs=25, is_inception=False, early_stopping=None):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "    val_loss_history = []\n",
        "    train_acc_history = []\n",
        "    train_loss_history = []\n",
        "    lr_find_lr = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # train과 val 단계에 따라 model 모드 변경\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in tqdm_notebook(dataloaders[phase]):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # train 모드라면 hitstory 저장\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # inception module을 사용하는 모델인경우 loss 설정\n",
        "                    if is_inception and phase == 'train':\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = cost(outputs, labels)\n",
        "                        loss2 = cost(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = cost(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimizer + scheduler\n",
        "                    # scheduler의 경우 일단 비활성화\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                        #scheduler.step()\n",
        "                        #lr_step = optimizer_ft.state_dict()[\"param_groups\"][0][\"lr\"]\n",
        "                        #lr_find_lr.append(lr_step)\n",
        "\n",
        "                # 현재 에포크의 손실 저장\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # loss, acc 계산\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # 현재 epoch의 정확도가 best_acc 보다 큰 경우 best 모델을 변경\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            # 현재 epoch의 정확도를 history에 저장\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "                val_loss_history.append(epoch_loss)\n",
        "            else:\n",
        "                train_acc_history.append(epoch_acc)\n",
        "                train_loss_history.append(epoch_loss)\n",
        "\n",
        "        print()\n",
        "        if early_stopping is not None:\n",
        "            early_stopping(val_loss_history[-1], model)\n",
        "            if early_stopping.early_stop: # 조건 만족 시 조기 종료\n",
        "                break\n",
        "\n",
        "    # 학습시간 계산\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # best model 로드\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    history_val = {'loss': val_loss_history, 'acc': val_acc_history}\n",
        "    history_train = {'loss': train_loss_history, 'acc': train_acc_history}\n",
        "\n",
        "    return model, history_val, history_train, time_elapsed, lr_find_lr, best_acc"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:04:04.278962Z",
          "iopub.execute_input": "2025-05-17T13:04:04.279671Z",
          "iopub.status.idle": "2025-05-17T13:04:04.304529Z",
          "shell.execute_reply.started": "2025-05-17T13:04:04.279645Z",
          "shell.execute_reply": "2025-05-17T13:04:04.303842Z"
        },
        "id": "61oDXud2eT35"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## transfer learning 시 동작 설정 함수"
      ],
      "metadata": {
        "id": "jTuRZfQReT36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# feature_extracting이 설정된 경우 fc레이어의 param만 학습\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:04:04.306164Z",
          "iopub.execute_input": "2025-05-17T13:04:04.30689Z",
          "iopub.status.idle": "2025-05-17T13:04:04.324856Z",
          "shell.execute_reply.started": "2025-05-17T13:04:04.306864Z",
          "shell.execute_reply": "2025-05-17T13:04:04.32427Z"
        },
        "id": "EG3eT1tieT36"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.models로부터 모델을 불러오는 함수"
      ],
      "metadata": {
        "id": "Gbc9PWJGeT36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=False):\n",
        "\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet152\":\n",
        "        \"\"\" Resnet152\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet152(pretrained=use_pretrained)\n",
        "        # pretrained=true일때\n",
        "        # feature_extract=true인 경우 마지막 fc레이어의 param만 학습\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        # fc레이어의 input 개수 로드\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        # fc레이어의 output 개수 설정\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == 'resnet18':\n",
        "        \"\"\" ResNet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet161(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:04:04.325585Z",
          "iopub.execute_input": "2025-05-17T13:04:04.325866Z",
          "iopub.status.idle": "2025-05-17T13:04:04.348204Z",
          "shell.execute_reply.started": "2025-05-17T13:04:04.325847Z",
          "shell.execute_reply": "2025-05-17T13:04:04.347539Z"
        },
        "id": "MCem8ReNeT36"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터셋 클래스 생성"
      ],
      "metadata": {
        "id": "RRMxy9kheT38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpsonsDataset(Dataset):\n",
        "\n",
        "    def __init__(self, files_path, data_transforms):\n",
        "      self.files_path = files_path\n",
        "      self.transform = data_transforms\n",
        "\n",
        "      if 'test' not in str(self.files_path[0]):\n",
        "        self.labels = [path.parent.name for path in self.files_path]\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.label_encoder.fit(self.labels)\n",
        "\n",
        "        with open('label_encoder.pkl', 'wb') as le_dump_file:\n",
        "            pickle.dump(self.label_encoder, le_dump_file)\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.files_path)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "      img_path = str(self.files_path[idx])\n",
        "      image = Image.open(img_path)\n",
        "      image = self.transform(image)\n",
        "\n",
        "      if 'test' in str(self.files_path[0]):\n",
        "        return image\n",
        "      else:\n",
        "        label_str = str(self.files_path[idx].parent.name)\n",
        "        label = self.label_encoder.transform([label_str]).item()\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:04:04.348976Z",
          "iopub.execute_input": "2025-05-17T13:04:04.349285Z",
          "iopub.status.idle": "2025-05-17T13:04:04.364458Z",
          "shell.execute_reply.started": "2025-05-17T13:04:04.34926Z",
          "shell.execute_reply": "2025-05-17T13:04:04.363925Z"
        },
        "id": "u1BB3jEjeT38"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 설정"
      ],
      "metadata": {
        "id": "5V-xcZpVeT39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'resnet18'\n",
        "\n",
        "num_classes = TrainValTestPath.get_n_classes()\n",
        "batch_size = 32\n",
        "num_epochs = 2\n",
        "\n",
        "# device 설정\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# pretrained 모델을 이용하는 경우\n",
        "# feature_extract = False - 전체 모델 학습\n",
        "# feature_extract = True - Fc 레이어만 학습\n",
        "feature_extract = False\n",
        "\n",
        "save_last_weights_path = '/kaggle/working/' + model_name + '-' + '_last_weights.pth'\n",
        "save_best_weights_path = '/kaggle/working/' + model_name + '-' + '_best_weights.pth'"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:04:04.365007Z",
          "iopub.execute_input": "2025-05-17T13:04:04.36517Z",
          "iopub.status.idle": "2025-05-17T13:04:04.392946Z",
          "shell.execute_reply.started": "2025-05-17T13:04:04.365157Z",
          "shell.execute_reply": "2025-05-17T13:04:04.392367Z"
        },
        "id": "Xa8JCbkieT39"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=False)\n",
        "\n",
        "model_ft = model_ft.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:04:04.393895Z",
          "iopub.execute_input": "2025-05-17T13:04:04.39411Z",
          "iopub.status.idle": "2025-05-17T13:04:04.780852Z",
          "shell.execute_reply.started": "2025-05-17T13:04:04.394095Z",
          "shell.execute_reply": "2025-05-17T13:04:04.780055Z"
        },
        "id": "Bj0fD_1VeT39"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 Augmentation"
      ],
      "metadata": {
        "id": "GlCXRSD_eT3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) -> imagenet 데이터셋의 통계 기반\n",
        "# TODO\n",
        "# simpson 데이터셋 전체의 std와 mean 계산 후 정규화에 이용\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((input_size,input_size)),\n",
        "        #transforms.CenterCrop(input_size),\n",
        "        transforms.RandomChoice( [\n",
        "                                  transforms.RandomHorizontalFlip(p=0.5),\n",
        "                                  transforms.ColorJitter(contrast=0.9),\n",
        "                                  transforms.ColorJitter(brightness=0.1),\n",
        "                                  transforms.RandomApply( [ transforms.RandomHorizontalFlip(p=1), transforms.ColorJitter(contrast=0.9) ], p=0.5),\n",
        "                                  transforms.RandomApply( [ transforms.RandomHorizontalFlip(p=1), transforms.ColorJitter(brightness=0.1) ], p=0.5),\n",
        "                                  ] ),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((input_size,input_size)),\n",
        "        #transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:04:04.781666Z",
          "iopub.execute_input": "2025-05-17T13:04:04.781938Z",
          "iopub.status.idle": "2025-05-17T13:04:04.787865Z",
          "shell.execute_reply.started": "2025-05-17T13:04:04.781913Z",
          "shell.execute_reply": "2025-05-17T13:04:04.787156Z"
        },
        "id": "gB6orXxMeT3-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델에 전달될 데이터 설정"
      ],
      "metadata": {
        "id": "aoyC1xUaeT3-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "wBbCNMekeT3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_datasets = {mode: SimpsonsDataset(train_path[mode], data_transforms[mode]) for mode in ['train', 'val']}\n",
        "image_datasets_test = SimpsonsDataset(test_path, data_transforms['val'])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:04:04.791436Z",
          "iopub.execute_input": "2025-05-17T13:04:04.791632Z",
          "iopub.status.idle": "2025-05-17T13:04:04.840359Z",
          "shell.execute_reply.started": "2025-05-17T13:04:04.791618Z",
          "shell.execute_reply": "2025-05-17T13:04:04.839643Z"
        },
        "id": "G-hC7pO7eT3-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataloader"
      ],
      "metadata": {
        "id": "4jDjRJoJeT3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "g = torch.Generator()\n",
        "g.manual_seed(0)\n",
        "\n",
        "num_workers = 4\n",
        "dataloaders_dict = {'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True,\n",
        "                                                         num_workers=num_workers, worker_init_fn=seed_worker,generator=g),\n",
        "                    'val': torch.utils.data.DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=True,\n",
        "                                                       num_workers=num_workers,worker_init_fn=seed_worker,generator=g)}\n",
        "dataloader_test = torch.utils.data.DataLoader(image_datasets_test, batch_size=batch_size, shuffle=False,\n",
        "                                              num_workers=num_workers, worker_init_fn=seed_worker,generator=g)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:04:04.841114Z",
          "iopub.execute_input": "2025-05-17T13:04:04.841369Z",
          "iopub.status.idle": "2025-05-17T13:04:04.846887Z",
          "shell.execute_reply.started": "2025-05-17T13:04:04.841334Z",
          "shell.execute_reply": "2025-05-17T13:04:04.846099Z"
        },
        "id": "60dExOe9eT3_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 이미지 출력"
      ],
      "metadata": {
        "id": "QW0hpOZgeT3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(inp, title=None, plt_ax=plt, default=False):\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt_ax.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt_ax.set_title(title)\n",
        "    plt_ax.grid(False)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:04:04.847673Z",
          "iopub.execute_input": "2025-05-17T13:04:04.848021Z",
          "iopub.status.idle": "2025-05-17T13:04:04.869585Z",
          "shell.execute_reply.started": "2025-05-17T13:04:04.847976Z",
          "shell.execute_reply": "2025-05-17T13:04:04.868766Z"
        },
        "id": "nQBcNDFMeT4A"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(8, 8), \\\n",
        "                        sharey=True, sharex=True)\n",
        "for fig_x in ax.flatten():\n",
        "    random_characters = int(np.random.uniform(0, 4500))\n",
        "    im_val, label = image_datasets['train'][random_characters]\n",
        "    # 캐릭터 이름 출력\n",
        "    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n",
        "                image_datasets['val'].label_encoder.inverse_transform([label])[0].split('_')))\n",
        "    imshow(im_val.data.cpu(), \\\n",
        "          title=img_label,plt_ax=fig_x)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:04:04.870408Z",
          "iopub.execute_input": "2025-05-17T13:04:04.870652Z",
          "iopub.status.idle": "2025-05-17T13:04:06.384465Z",
          "shell.execute_reply.started": "2025-05-17T13:04:04.870632Z",
          "shell.execute_reply": "2025-05-17T13:04:06.383759Z"
        },
        "id": "TTEpHtDSeT4A"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 파라미터 설정"
      ],
      "metadata": {
        "id": "0csyfkpveT4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name, param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            #print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            pass\n",
        "            #print(\"\\t\",name)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:04:06.385275Z",
          "iopub.execute_input": "2025-05-17T13:04:06.385513Z",
          "iopub.status.idle": "2025-05-17T13:04:06.391597Z",
          "shell.execute_reply.started": "2025-05-17T13:04:06.385493Z",
          "shell.execute_reply": "2025-05-17T13:04:06.390873Z"
        },
        "id": "8BVIlJOBeT4D"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습"
      ],
      "metadata": {
        "id": "8XZps6UxeT4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=False)\n",
        "model_ft = model_ft.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:38:05.688827Z",
          "iopub.execute_input": "2025-05-17T13:38:05.6891Z",
          "iopub.status.idle": "2025-05-17T13:38:05.872654Z",
          "shell.execute_reply.started": "2025-05-17T13:38:05.689082Z",
          "shell.execute_reply": "2025-05-17T13:38:05.872094Z"
        },
        "id": "SbqhHcSieT4D"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name, param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            #print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            pass\n",
        "            #print(\"\\t\",name)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:04:06.597223Z",
          "iopub.execute_input": "2025-05-17T13:04:06.597415Z",
          "iopub.status.idle": "2025-05-17T13:04:06.603472Z",
          "shell.execute_reply.started": "2025-05-17T13:04:06.597401Z",
          "shell.execute_reply": "2025-05-17T13:04:06.602909Z"
        },
        "id": "KYfHnJcWeT4D"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#base_lr = 0.0012\n",
        "#max_lr = 0.0022\n",
        "num_epoch = 30\n",
        "\n",
        "cost = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9, nesterov = True)\n",
        "#step_size = 2 * math.ceil( len(dataloaders_dict['train']) / batch_size )\n",
        "#scheduler = optim.lr_scheduler.CyclicLR(optimizer_ft, base_lr = base_lr, max_lr = max_lr, step_size_up=step_size, mode='exp_range', gamma=0.994, scale_mode='cycle', cycle_momentum=True, base_momentum=0.8, max_momentum=0.9, last_epoch=-1)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:04:06.60411Z",
          "iopub.execute_input": "2025-05-17T13:04:06.604338Z",
          "iopub.status.idle": "2025-05-17T13:04:06.61766Z",
          "shell.execute_reply.started": "2025-05-17T13:04:06.604314Z",
          "shell.execute_reply": "2025-05-17T13:04:06.617148Z"
        },
        "id": "aTOh3kY0eT4E"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss = []\n",
        "val_acc = []\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "lr_cycle = []\n",
        "best_acc = .0"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:04:06.618324Z",
          "iopub.execute_input": "2025-05-17T13:04:06.61849Z",
          "iopub.status.idle": "2025-05-17T13:04:06.63313Z",
          "shell.execute_reply.started": "2025-05-17T13:04:06.618477Z",
          "shell.execute_reply": "2025-05-17T13:04:06.632497Z"
        },
        "id": "BWTZOOWVeT4E"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(patience = 3, verbose = True, delta = 0.005)\n",
        "\n",
        "image_datasets = {mode: SimpsonsDataset(train_path[mode], data_transforms[mode]) for mode in ['train', 'val']}\n",
        "\n",
        "dataloaders_dict = {'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True, num_workers=0,\n",
        "                                                    worker_init_fn=seed_worker,generator=g),\n",
        "                  'val': torch.utils.data.DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=False, num_workers=0,\n",
        "                                                    worker_init_fn=seed_worker,generator=g)}\n",
        "\n",
        "model, history_val, history_train, time_elapsed, lr_find_lr, best_acc = train_model(model_ft, dataloaders_dict, cost, optimizer_ft, save_best_weights_path, save_last_weights_path, best_acc = best_acc, num_epochs=num_epoch, is_inception=(model_name==\"inception\"), early_stopping = es)\n",
        "\n",
        "val_loss += history_val['loss']\n",
        "val_acc += history_val['acc']\n",
        "train_loss += history_train['loss']\n",
        "train_acc += history_train['acc']\n",
        "lr_cycle += lr_find_lr"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:04:06.633706Z",
          "iopub.execute_input": "2025-05-17T13:04:06.633927Z",
          "iopub.status.idle": "2025-05-17T13:37:56.402411Z",
          "shell.execute_reply.started": "2025-05-17T13:04:06.633912Z",
          "shell.execute_reply": "2025-05-17T13:37:56.401038Z"
        },
        "id": "8Ie0RK6geT4E"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습 결과 및 모델 분석"
      ],
      "metadata": {
        "id": "D3sk9jjUeT4F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습 결과 시각화 함수"
      ],
      "metadata": {
        "id": "Bd77lifzeT4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualization(train, val, is_loss = True):\n",
        "  if is_loss:\n",
        "    plt.figure(figsize=(9,5))\n",
        "    plt.plot(torch.tensor(train, device =  'cpu'), label = 'Training loss')\n",
        "    plt.plot(torch.tensor(val, device =  'cpu'), label = 'Val loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "  else:\n",
        "    plt.figure(figsize=(9,5))\n",
        "    plt.plot(torch.tensor(train, device =  'cpu'), label = 'Training acc')\n",
        "    plt.plot(torch.tensor(val, device =  'cpu'), label = 'Val acc')\n",
        "    plt.title('Training and validation acc')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Acc')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:37:56.403107Z",
          "iopub.status.idle": "2025-05-17T13:37:56.403328Z",
          "shell.execute_reply.started": "2025-05-17T13:37:56.403219Z",
          "shell.execute_reply": "2025-05-17T13:37:56.403229Z"
        },
        "id": "a_jHdlVyeT4F"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## confusion_matrix for val data"
      ],
      "metadata": {
        "id": "fhxdcQB2eT4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, test_loader):\n",
        "    with torch.no_grad():\n",
        "        logits = []\n",
        "\n",
        "        for inputs in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            model.eval()\n",
        "            outputs = model(inputs).cpu()\n",
        "            logits.append(outputs)\n",
        "\n",
        "    probs = nn.functional.softmax(torch.cat(logits), dim=1).numpy()\n",
        "    return probs"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:37:56.404465Z",
          "iopub.status.idle": "2025-05-17T13:37:56.4048Z",
          "shell.execute_reply.started": "2025-05-17T13:37:56.404624Z",
          "shell.execute_reply": "2025-05-17T13:37:56.404638Z"
        },
        "id": "IYEicqKheT4G"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion_matrix\n",
        "actual = [image_datasets['val'][i][1] for i in range( len(image_datasets['val']) ) ]\n",
        "image = [image_datasets['val'][i][0] for i in range( len(image_datasets['val']) ) ]\n",
        "img_conf_dataloader = torch.utils.data.DataLoader(image, batch_size=batch_size, shuffle=False, num_workers=4,\n",
        "                                                 worker_init_fn=seed_worker,generator=g)\n",
        "probs = predict(model_ft, img_conf_dataloader)\n",
        "preds = np.argmax(probs, axis=1)\n",
        "\n",
        "df = pd.DataFrame({'actual': actual, 'preds': preds})\n",
        "confusion_matrix = pd.crosstab(df['actual'], df['preds'], rownames=['Actual'], colnames=['Predicted'], margins = False)\n",
        "label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))\n",
        "yticklabels = label_encoder.classes_\n",
        "plt.subplots(figsize=(20,20))\n",
        "sn.heatmap(confusion_matrix, annot=True, fmt=\"d\", linewidths=0.5, cmap=\"YlGnBu\", cbar=False, vmax = 30, yticklabels = yticklabels, xticklabels = label_encoder.classes_[np.unique(preds)]);"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:37:56.405707Z",
          "iopub.status.idle": "2025-05-17T13:37:56.406033Z",
          "shell.execute_reply.started": "2025-05-17T13:37:56.405858Z",
          "shell.execute_reply": "2025-05-17T13:37:56.405872Z"
        },
        "id": "A2ygXLtBeT4G"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## lr_cycle, acc, loss 시각화"
      ],
      "metadata": {
        "id": "tZ1V_USkeT4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plt.figure(figsize=(17,10))\n",
        "#plt.plot(lr_cycle);"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:37:56.407158Z",
          "iopub.status.idle": "2025-05-17T13:37:56.407477Z",
          "shell.execute_reply.started": "2025-05-17T13:37:56.407311Z",
          "shell.execute_reply": "2025-05-17T13:37:56.407326Z"
        },
        "id": "BYKETmOXeT4H"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "visualization(train_acc, val_acc, is_loss = False)\n",
        "print('\\n')\n",
        "visualization(train_loss, val_loss, is_loss = True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:37:56.408669Z",
          "iopub.status.idle": "2025-05-17T13:37:56.409004Z",
          "shell.execute_reply.started": "2025-05-17T13:37:56.408847Z",
          "shell.execute_reply": "2025-05-17T13:37:56.408861Z"
        },
        "id": "wnN-bCPleT4H"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 테스트"
      ],
      "metadata": {
        "id": "yUBqk79OeT4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 샘플 테스트"
      ],
      "metadata": {
        "id": "lw57dVtyeT4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_one_sample(model, img_tensor, device=device):\n",
        "    with torch.no_grad():\n",
        "        img_tensor = img_tensor.to(device)\n",
        "        model.eval()\n",
        "        y_hat = model(img_tensor).cpu()\n",
        "        y_pred = torch.nn.functional.softmax(y_hat, dim=1).numpy()\n",
        "    return y_pred"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:37:56.411161Z",
          "iopub.status.idle": "2025-05-17T13:37:56.41138Z",
          "shell.execute_reply.started": "2025-05-17T13:37:56.411274Z",
          "shell.execute_reply": "2025-05-17T13:37:56.411282Z"
        },
        "id": "t-8rakMWeT4I"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 테스트 샘플 시각화"
      ],
      "metadata": {
        "id": "B7XJTPUJeT4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.patches as patches\n",
        "from matplotlib.font_manager import FontProperties\n",
        "\n",
        "fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(12, 12), \\\n",
        "                        sharey=True, sharex=True)\n",
        "\n",
        "label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))\n",
        "\n",
        "for fig_x in ax.flatten():\n",
        "    random_characters = int(np.random.uniform(0, 1000))\n",
        "    im_val, label = image_datasets['val'][random_characters]\n",
        "    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n",
        "                image_datasets['val'].label_encoder.inverse_transform([label])[0].split('_')))\n",
        "\n",
        "    imshow(im_val.data.cpu(), \\\n",
        "          title=img_label, plt_ax=fig_x)\n",
        "\n",
        "    actual_text = \"Actual : {}\".format(img_label)\n",
        "\n",
        "    fig_x.add_patch(patches.Rectangle((1, 189), 120, 35, color='white'))\n",
        "    font0 = FontProperties()\n",
        "    font = font0.copy()\n",
        "    prob_pred = predict_one_sample(model_ft, im_val.unsqueeze(0))ь\n",
        "    predicted_proba = np.max(prob_pred)*100\n",
        "    y_pred = np.argmax(prob_pred)\n",
        "\n",
        "    predicted_label = label_encoder.classes_[y_pred]\n",
        "    predicted_text = \"{} :\\n {:.0f}%\".format(predicted_label,predicted_proba)\n",
        "\n",
        "    fig_x.text(1, 189, predicted_text , horizontalalignment='left', fontproperties=font,\n",
        "                    verticalalignment='top',fontsize=8, color='black',fontweight='bold')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:37:56.412444Z",
          "iopub.status.idle": "2025-05-17T13:37:56.412776Z",
          "shell.execute_reply.started": "2025-05-17T13:37:56.412593Z",
          "shell.execute_reply": "2025-05-17T13:37:56.412608Z"
        },
        "id": "2TKFeth4eT4J"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 테스트셋에 대한 평가 지표"
      ],
      "metadata": {
        "id": "wDujq_LteT4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "probs = predict(model_ft, dataloader_test)\n",
        "\n",
        "label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))\n",
        "\n",
        "preds = label_encoder.inverse_transform(np.argmax(probs, axis = 1 ))\n",
        "test_file_names = [path.name for path in image_                     datasets_test.files_path]\n",
        "\n",
        "for i in range(len(test_file_names)):\n",
        "  test_file_names[i] = test_file_names[i].split('.')[0].rsplit('_', 1)[0]\n",
        "\n",
        "present_labels = np.unique(test_file_names)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_file_names, preds, labels=present_labels))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:37:56.414098Z",
          "iopub.status.idle": "2025-05-17T13:37:56.414399Z",
          "shell.execute_reply.started": "2025-05-17T13:37:56.414237Z",
          "shell.execute_reply": "2025-05-17T13:37:56.414251Z"
        },
        "id": "cXE5Uxs-eT4K"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#for i in range(len(test_file_names)):\n",
        "#    print(test_file_names[i])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:37:56.415541Z",
          "iopub.status.idle": "2025-05-17T13:37:56.415829Z",
          "shell.execute_reply.started": "2025-05-17T13:37:56.415664Z",
          "shell.execute_reply": "2025-05-17T13:37:56.415676Z"
        },
        "id": "ONFCvrBOeT4K"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#my_submit = pd.DataFrame({'Id': test_filenames, 'Expected': preds})\n",
        "#my_submit.head()\n",
        "#my_submit.to_csv('simspsons.csv', index=False)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:37:56.416748Z",
          "iopub.status.idle": "2025-05-17T13:37:56.417033Z",
          "shell.execute_reply.started": "2025-05-17T13:37:56.416879Z",
          "shell.execute_reply": "2025-05-17T13:37:56.416894Z"
        },
        "id": "GILbpP0MeT4L"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}